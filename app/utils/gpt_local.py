import requests
from app.config import OLLAMA_GENERATE_ENDPOINT, OLLAMA_MODEL_NAME
import re

def generate_category_name(todo: str) -> str:
    prompt = f"""
    "{todo}" ì´ í™œë™ì„ ëŒ€í‘œí•˜ëŠ” ìƒìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ í•œêµ­ì–´ë¡œ í•œ ë‹¨ì–´ë¡œë§Œ ë§í•´ì£¼ì„¸ìš”.
    ì¡°ê±´: íŠ¹ìˆ˜ë¬¸ì ì—†ì´, ì˜ë¯¸ ìˆëŠ” ìƒìœ„ ì¹´í…Œê³ ë¦¬ ë‹¨ì–´ë§Œ, "ê¸°íƒ€"ëŠ” ê¸ˆì§€.
    ì¶œë ¥: í•œ ë‹¨ì–´ (ì˜ˆ: ìš´ë™, ì—¬í–‰, ê³µë¶€, ì²­ì†Œ, ê³„íš, ì‡¼í•‘, ë…ì„œ, ìš”ë¦¬, ì •ë¦¬, íšŒì˜)
    """

    print("[ğŸŸ¡ ìš”ì²­ ì „ì†¡]")
    print(f"ëª¨ë¸: {OLLAMA_MODEL_NAME}")
    # print(f"í”„ë¡¬í”„íŠ¸: {prompt.strip()}")

    try:
        response = requests.post(OLLAMA_GENERATE_ENDPOINT, json={
            "model": OLLAMA_MODEL_NAME,
            "prompt": prompt,
            "stream": False,
            "max_tokens": 10,  # ì¶œë ¥ ê¸¸ì´ ì œí•œ
            "temperature": 0.5  # ìƒì„± í…ìŠ¤íŠ¸ì˜ ë‹¤ì–‘ì„± ì¡°ì •
        })

        print("[ğŸŸ¢ ì‘ë‹µ ë„ì°©]")
        # print("Status:", response.status_code)

        if response.status_code == 200:
            data = response.json()
            

            if "response" in data:
                raw = data["response"]
                cleaned = raw.strip().splitlines()[0]  # ì²« ì¤„ë§Œ ê°€ì ¸ì˜¤ê¸°
                cleaned = cleaned.strip().strip('"')  # ë”°ì˜´í‘œ ì œê±°
                cleaned = re.sub(r"[^\uAC00-\uD7A3]", "", cleaned)  # í•œê¸€ë§Œ ë‚¨ê¸°ê¸°
                print("ì‘ë‹µ ë‚´ìš©:", cleaned)
                return cleaned

            elif "message" in data:
                return data["message"].strip().split("\n")[0]
            else:
                return "ê¸°íƒ€"
        else:
            print("ë¹„ì •ìƒ ì‘ë‹µ â†’ ê¸°íƒ€ ë°˜í™˜")
            return "ê¸°íƒ€"

    except Exception as e:
        print("âš ï¸ ì˜ˆì™¸ ë°œìƒ:", e)
        return "ê¸°íƒ€"
